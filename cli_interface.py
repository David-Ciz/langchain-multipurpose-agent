import logging
import os

import click
from langchain.memory import ConversationBufferMemory
from langchain_community.vectorstores.pinecone import Pinecone
from langchain_experimental.tools import PythonREPLTool

from agents.orchestrator_agent import OrchestratorAgent
from agents.vectorstore_agent import VectorStoreAgent
from documentation_loader import update_docs_database
from langchain_community.tools.ddg_search import DuckDuckGoSearchRun
from langchain_openai import ChatOpenAI,  OpenAIEmbeddings
from dotenv import load_dotenv

from utils import env_variables_checker

load_dotenv()
logger = logging.getLogger("Assistant")
INDEX_NAME = os.environ["INDEX_NAME"]

missing_variables = env_variables_checker()
if missing_variables:
    logging.warning(f'warning, you are missing the following env. variables: {missing_variables}')


@click.group()
def cli():
    pass


@cli.command("update-docs")
@click.option("--documentation_url",type=str, default="https://ibm.github.io/ibm-generative-ai/",
              help="Optional argument if the url changes. defaults to https://ibm.github.io/ibm-generative-ai/")
def update_docs_database_cli(documentation_url: str):
    """
    Updates the PINECONE database with new documents when called. It expects the document structure to be
    generated by Sphinx.
    """
    update_docs_database()


@cli.command("start-chat")
@click.option("--verbose", type=bool, default="False", help="Verbosity of chain of though")
def start_chat_cli(verbose: bool):
    """
    Starts an interactive chat with the agent in the terminal. To exit the chat, type "exit".
    """

    welcome_ai_message = " Hello, I'm a cli helpful assistant that can answer questions from the documentation. " \
                         "I can search internet for you and execute python code!"

    vectorstore = Pinecone.from_existing_index(INDEX_NAME, OpenAIEmbeddings())
    llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0.2, streaming=True)
    documentation_agent = VectorStoreAgent(llm=llm, vectorstore=vectorstore)
    # memory setup with resetting button.
    memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True,
                                      output_key="output")

    tools = [DuckDuckGoSearchRun(name="Search"), PythonREPLTool(), documentation_agent.as_tool()]
    orchestrator_agent = OrchestratorAgent(tools, llm, memory, return_intermediate_steps=verbose)

    print(welcome_ai_message)
    while True:
        print("\n Continue by writing your question or request below, type 'exit' to quit and 'reset' to reset the "
              "memory")
        user_input = input()
        if user_input == "exit":
            break
        elif user_input == "reset":
            memory.clear()
        else:
            orchestrator_agent.get_cli_response(user_input, verbose=verbose)


if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    cli()
